{"name":"Taotao","tagline":"noting","body":"title: 用Python实现Python解释器\r\nauthor: Allison Kaptur\r\ntranslator：陶青云\r\n\r\n_Allison是Dropbox的工程师，在那里她维护着世界上最大的由Python客户组成的网络。在Dropbox之前，她是Recurse Center的引导师, ... 她在北美的PyCon做过关于Python内部机制的演讲，并且她喜欢奇怪的bugs。她的博客地址是[akaptur.com](http://akaptur.com)._\r\n\r\n## Introduction\r\n\r\nByterun是一个用Python实现的Python解释器。随着我在Byterun上的工作，我惊讶并很高兴地的发现，这个Python解释器的基础结构可以满足500行的限制。在这一章我们会搞清楚这个解释器的结构，给你足够的知识探索下去。我们的目标不是向你展示解释器的每个细节---像编程和计算机科学其他有趣的领域一样，你可能会投入几年的时间去搞清楚这个主题。\r\n\r\nByterun是Ned Batchelder和我完成的，建立在Paul Swartz的工作之上。它的结构和主要的Python实现（CPython）差不多，所以理解Byterun会帮助你理解大多数解释器特别是CPython解释器。（如果你不知道你用的是什么Python，那么很可能它就是CPython）。尽管Byterun不到500行，但它能执行大多数简单的Python程序。\r\n\r\n### A Python Interpreter\r\n\r\n在开始之前，让我们缩小一下“Pyhton解释器”的意思。在讨论Python的时候，“解释器”这个词可以用在很多不同的地方。有的时候解释器指的是REPL，当你在命令行下敲下`python`时所得到的交互式环境。有时候人们会相互替代的使用Python解释器和Python来说明执行Python代码的这一过程。在本章，“解释器”有一个更精确的意思：执行Python程序过程中的最后一步。\r\n\r\n在解释器接手之前，Python会执行其他3个步骤：词法分析，语法解析和编译。这三步合起来把源代码转换成_code object_,它包含着解释器可以理解的指令。而解释器的工作就是解释code object中的指令。\r\n\r\n你可能很奇怪执行Python代码会有编译这一步。Python通常被称为解释型语言，就像Ruby，Perl一样，它们和编译型语言相对，比如C，Rust。然而，这里的术语并不是它看起来的那样精确。大多数解释型语言包括Python，确实会有编译这一步。而Python被称为解释型的原因是相对于编译型语言，它在编译这一步的工作相对较少（解释器做相对多的工作）。在这章后面你会看到，Python的编译器比C语言编译器需要更少的关于程序行为的信息。\r\n\r\n### A Python Python Interpreter\r\n\r\nByterun是一个用Python写的Python解释器，这点可能让你感到奇怪，但没有比用C语言写C语言编译器更奇怪。（事实上，广泛使用的gcc编译器就是用C语言本身写的）你可以用几乎的任何语言写一个Python解释器。\r\n\r\n用Python写Python既有有点又有缺点。最大的缺点就是速度：用Byterun执行代码要比用CPython执行慢的多，CPython解释器是用C语言实现的并做了优化。然而Byterun是为了学习而设计的，所以速度对我们不重要。使用Python最大优点是我们可以*仅仅*实现解释器，而不用担心Python运行时的部分，特别是对象系统。比如当Byterun需要创建一个类时，它就会回退到“真正”的Python。另外一个优势是Byterun很容易理解，部分原因是它是用高级语言写的（Python！）（另外我们不会对解释器做优化 --- 再一次，清晰和简单比速度更重要）\r\n\r\n## Building an Interpreter\r\n\r\n在我们考察Byterun代码之前，我们需要一些对解释器的结构的高层次视角。Python解释器是如何工作的？\r\n\r\nPython解释器是一个_虚拟机_,模拟真实的计算机的软件。我们这个虚拟机是栈机器，它用几个栈来完成操作（与之相对的是寄存器机器，它从特定的内存地址读写数据）。\r\n\r\nPython解释器是一个_字节码解释器_：它的输入是一些命令集合称作_字节码_。当你写Python代码时，词法分析器，语法解析器和编译器生成code object让解释器去操作。每个code object都包含一个要被执行的指令集合 --- 它就是字节码 --- 另外还有一些解释器需要的信息。字节码是Python代码的一个_中间层表示_：它以一种解释器可以理解的方式来表示源代码。这和汇编语言作为C语言和机器语言的中间表示很类似。\r\n\r\n### A Tiny Interpreter\r\n\r\nTo make this concrete, let's start with a very minimal interpreter. This interpreter can only add numbers, and it understands just three instructions. All code it can execute consists of these three instructions in different combinations. The three instructions are these:\r\n\r\n- `LOAD_VALUE`\r\n- `ADD_TWO_VALUES`\r\n- `PRINT_ANSWER`\r\n\r\nSince we're not concerned with the lexer, parser, and compiler in this chapter, it doesn't matter how the instruction sets are produced.  You can imagine writing `7 + 5` and having a compiler emit a combination of these three instructions. Or, if you have the right compiler, you can write Lisp syntax that's turned into the same combination of instructions. The interpreter doesn't care. All that matters is that our interpreter is given a well-formed arrangement of the instructions.\r\n\r\nSuppose that\r\n\r\n```python\r\n7 + 5\r\n```\r\n\r\nproduces this instruction set:\r\n\r\n```python\r\nwhat_to_execute = {\r\n    \"instructions\": [(\"LOAD_VALUE\", 0),  # the first number\r\n                     (\"LOAD_VALUE\", 1),  # the second number\r\n                     (\"ADD_TWO_VALUES\", None),\r\n                     (\"PRINT_ANSWER\", None)],\r\n    \"numbers\": [7, 5] }\r\n```\r\n\r\nThe Python interpreter is a _stack machine_, so it must manipulate stacks to add two numbers (\\aosafigref{500l.interpreter.stackmachine}.) The interpreter will begin by executing the first instruction, `LOAD_VALUE`, and pushing the first number onto the stack. Next it will push the second number onto the stack. For the third instruction, `ADD_TWO_VALUES`, it will pop both numbers off, add them together, and push the result onto the stack. Finally, it will pop the answer back off the stack and print it.\r\n\r\n\\aosafigure[240pt]{interpreter-images/interpreter-stack.png}{A stack machine}{500l.interpreter.stackmachine}\r\n\r\nThe `LOAD_VALUE` instruction tells the interpreter to push a number on to the stack, but the instruction alone doesn't specify which number. Each instruction needs an extra piece of information, telling the interpreter where to find the number to load. So our instruction set has two pieces: the instructions themselves, plus a list of constants the instructions will need. (In Python, what we're calling \"instructions\" is the bytecode, and the entire \"what to execute\" object below is the _code object_.)\r\n\r\nWhy not just put the numbers directly in the instructions? Imagine if we were adding strings together instead of numbers. We wouldn't want to have the strings stuffed in with the instructions, since they could be arbitrarily large. This design also means we can have just one copy of each object that we need, so for example to add `7 + 7`, `\"numbers\"` could be just `[7]`.\r\n\r\nYou may be wondering why instructions other than `ADD_TWO_VALUES` were needed at all. Indeed, for the simple case of adding two numbers, the example is a little contrived. However, this instruction is a building block for more complex programs. For example, with just the instructions we've defined so far, we can already add together three values --- or any number of values --- given the right set of these instructions. The stack provides a clean way to keep track of the state of the interpreter, and it will support more complexity as we go along.\r\n\r\nNow let's start to write the interpreter itself. The interpreter object has a stack, which we'll represent with a list. The object also has a method describing how to execute each instruction. For example, for `LOAD_VALUE`, the interpreter will push the value onto the stack.\r\n\r\n```python\r\nclass Interpreter:\r\n    def __init__(self):\r\n        self.stack = []\r\n\r\n    def LOAD_VALUE(self, number):\r\n        self.stack.append(number)\r\n\r\n    def PRINT_ANSWER(self):\r\n        answer = self.stack.pop()\r\n        print(answer)\r\n\r\n    def ADD_TWO_VALUES(self):\r\n        first_num = self.stack.pop()\r\n        second_num = self.stack.pop()\r\n        total = first_num + second_num\r\n        self.stack.append(total)\r\n```\r\n\r\nThese three functions implement the three instructions our interpreter understands. The interpreter needs one more piece: a way to tie everything together and actually execute it. This method, `run_code`, takes the `what_to_execute` dictionary defined above as an argument. It loops over each instruction, processes the arguments to that instruction if there are any, and then calls the corresponding method on the interpreter object.\r\n\r\n```python\r\n    def run_code(self, what_to_execute):\r\n        instructions = what_to_execute[\"instructions\"]\r\n        numbers = what_to_execute[\"numbers\"]\r\n        for each_step in instructions:\r\n            instruction, argument = each_step\r\n            if instruction == \"LOAD_VALUE\":\r\n                number = numbers[argument]\r\n                self.LOAD_VALUE(number)\r\n            elif instruction == \"ADD_TWO_VALUES\":\r\n                self.ADD_TWO_VALUES()\r\n            elif instruction == \"PRINT_ANSWER\":\r\n                self.PRINT_ANSWER()\r\n```\r\n\r\nTo test it out, we can create an instance of the object and then call the `run_code` method with the instruction set for adding 7 + 5 defined above.\r\n\r\n```python\r\n    interpreter = Interpreter()\r\n    interpreter.run_code(what_to_execute)\r\n```\r\n\r\nSure enough, it prints the answer: 12.\r\n\r\nAlthough this interpreter is quite limited, this process is almost exactly how the real Python interpreter adds numbers. There are a couple of things to note even in this small example.  \r\n\r\nFirst of all, some instructions need arguments. In real Python bytecode, about half of instructions have arguments. The arguments are packed in with the instructions, much like in our example. Notice that the arguments to the _instructions_ are different than the arguments to the methods that are called.\r\n\r\nSecond, notice that the instruction for `ADD_TWO_VALUES` did not require any arguments. Instead, the values to be added together were popped off the interpreter's stack. This is the defining feature of a stack-based interpreter.\r\n\r\nRemember that given valid instruction sets, without any changes to our interpreter, we can add more than two numbers at a time. Consider the instruction set below. What do you expect to happen? If you had a friendly compiler, what code could you write to generate this instruction set?\r\n\r\n```python\r\n    what_to_execute = {\r\n        \"instructions\": [(\"LOAD_VALUE\", 0),\r\n                         (\"LOAD_VALUE\", 1),\r\n                         (\"ADD_TWO_VALUES\", None),\r\n                         (\"LOAD_VALUE\", 2),\r\n                         (\"ADD_TWO_VALUES\", None),\r\n                         (\"PRINT_ANSWER\", None)],\r\n        \"numbers\": [7, 5, 8] }\r\n```\r\n\r\nAt this point, we can begin to see how this structure is extensible: we can add methods on the interpreter object that describe many more operations (as long as we have a compiler to hand us well-formed instruction sets).\r\n\r\n#### Variables\r\n\r\nNext let's add variables to our interpreter. Variables require an instruction for storing the value of a variable, `STORE_NAME`; an instruction for retrieving it, `LOAD_NAME`; and a mapping from variable names to values. For now, we'll ignore namespaces and scoping, so we can store the variable mapping on the interpreter object itself. Finally, we'll have to make sure that `what_to_execute` has a list of the variable names, in addition to its list of constants.\r\n\r\n```python\r\n>>> def s():\r\n...     a = 1\r\n...     b = 2\r\n...     print(a + b)\r\n# a friendly compiler transforms `s` into:\r\n    what_to_execute = {\r\n        \"instructions\": [(\"LOAD_VALUE\", 0),\r\n                         (\"STORE_NAME\", 0),\r\n                         (\"LOAD_VALUE\", 1),\r\n                         (\"STORE_NAME\", 1),\r\n                         (\"LOAD_NAME\", 0),\r\n                         (\"LOAD_NAME\", 1),\r\n                         (\"ADD_TWO_VALUES\", None),\r\n                         (\"PRINT_ANSWER\", None)],\r\n        \"numbers\": [1, 2],\r\n        \"names\":   [\"a\", \"b\"] }\r\n```\r\n\r\nOur new implementation is below. To keep track of what names are bound to what values, we'll add an `environment` dictionary to the `__init__` method. We'll also add `STORE_NAME` and `LOAD_NAME`. These methods first look up the variable name in question and then use the dictionary to store or retrieve its value.\r\n\r\nThe arguments to an instruction can now mean two different things: They can either be an index into the \"numbers\" list, or they can be an index into the \"names\" list. The interpreter knows which it should be by checking what instruction it's executing. We'll break out this logic --- and the mapping of instructions to what their arguments mean --- into a separate method.\r\n\r\n```python\r\nclass Interpreter:\r\n    def __init__(self):\r\n        self.stack = []\r\n        self.environment = {}\r\n\r\n    def STORE_NAME(self, name):\r\n        val = self.stack.pop()\r\n        self.environment[name] = val\r\n\r\n    def LOAD_NAME(self, name):\r\n        val = self.environment[name]\r\n        self.stack.append(val)\r\n\r\n    def parse_argument(self, instruction, argument, what_to_execute):\r\n        \"\"\" Understand what the argument to each instruction means.\"\"\"\r\n        numbers = [\"LOAD_VALUE\"]\r\n        names = [\"LOAD_NAME\", \"STORE_NAME\"]\r\n\r\n        if instruction in numbers:\r\n            argument = what_to_execute[\"numbers\"][argument]\r\n        elif instruction in names:\r\n            argument = what_to_execute[\"names\"][argument]\r\n\r\n        return argument\r\n\r\n    def run_code(self, what_to_execute):\r\n        instructions = what_to_execute[\"instructions\"]\r\n        for each_step in instructions:\r\n            instruction, argument = each_step\r\n            argument = self.parse_argument(instruction, argument, what_to_execute)\r\n\r\n            if instruction == \"LOAD_VALUE\":\r\n                self.LOAD_VALUE(argument)\r\n            elif instruction == \"ADD_TWO_VALUES\":\r\n                self.ADD_TWO_VALUES()\r\n            elif instruction == \"PRINT_ANSWER\":\r\n                self.PRINT_ANSWER()\r\n            elif instruction == \"STORE_NAME\":\r\n                self.STORE_NAME(argument)\r\n            elif instruction == \"LOAD_NAME\":\r\n                self.LOAD_NAME(argument)\r\n```\r\n\r\nEven with just five instructions, the `run_code` method is starting to get tedious. If we kept this structure, we'd need one branch of the `if` statement for each instruction. Here, we can make use of Python's dynamic method lookup. We'll always define a method called `FOO` to execute the instruction called `FOO`, so we can use Python's `getattr` function to look up the method on the fly instead of using the big `if` statement. The `run_code` method then looks like this:\r\n\r\n```python\r\n    def execute(self, what_to_execute):\r\n        instructions = what_to_execute[\"instructions\"]\r\n        for each_step in instructions:\r\n            instruction, argument = each_step\r\n            argument = self.parse_argument(instruction, argument, what_to_execute)\r\n            bytecode_method = getattr(self, instruction)\r\n            if argument is None:\r\n                bytecode_method()\r\n            else:\r\n                bytecode_method(argument)\r\n```\r\n\r\n## Real Python Bytecode\r\n\r\nAt this point, we'll abandon our toy instruction sets and switch to real Python bytecode. The structure of bytecode is similar to our toy interpreter's verbose instruction sets, except that it uses one byte instead of a long name to identify each instruction. To understand this structure, we'll walk through the bytecode of a short function. Consider the example below:\r\n\r\n```python\r\n>>> def cond():\r\n...     x = 3\r\n...     if x < 5:\r\n...         return 'yes'\r\n...     else:\r\n...         return 'no'\r\n...\r\n```\r\n\r\nPython exposes a boatload of its internals at run time, and we can access them right from the REPL. For the function object `cond`, `cond.__code__` is the code object associated it, and `cond.__code__.co_code` is the bytecode. There's almost never a good reason to use these attributes directly when you're writing Python code, but they do allow us to get up to all sorts of mischief --- and to look at the internals in order to understand them.\r\n\r\n```python\r\n>>> cond.__code__.co_code  # the bytecode as raw bytes\r\nb'd\\x01\\x00}\\x00\\x00|\\x00\\x00d\\x02\\x00k\\x00\\x00r\\x16\\x00d\\x03\\x00Sd\\x04\\x00Sd\\x00\r\n   \\x00S'\r\n>>> list(cond.__code__.co_code)  # the bytecode as numbers\r\n[100, 1, 0, 125, 0, 0, 124, 0, 0, 100, 2, 0, 107, 0, 0, 114, 22, 0, 100, 3, 0, 83, \r\n 100, 4, 0, 83, 100, 0, 0, 83]\r\n```\r\n\r\nWhen we just print the bytecode, it looks unintelligible --- all we can tell is that it's a series of bytes. Luckily, there's a powerful tool we can use to understand it: the `dis` module in the Python standard library. \r\n\r\n`dis` is a bytecode disassembler. A disassembler takes low-level code that is written for machines, like assembly code or bytecode, and prints it in a human-readable way. When we run `dis.dis`, it outputs an explanation of the bytecode it has passed.\r\n\r\n```python\r\n>>> dis.dis(cond)\r\n  2           0 LOAD_CONST               1 (3)\r\n              3 STORE_FAST               0 (x)\r\n\r\n  3           6 LOAD_FAST                0 (x)\r\n              9 LOAD_CONST               2 (5)\r\n             12 COMPARE_OP               0 (<)\r\n             15 POP_JUMP_IF_FALSE       22\r\n\r\n  4          18 LOAD_CONST               3 ('yes')\r\n             21 RETURN_VALUE\r\n\r\n  6     >>   22 LOAD_CONST               4 ('no')\r\n             25 RETURN_VALUE\r\n             26 LOAD_CONST               0 (None)\r\n             29 RETURN_VALUE\r\n```\r\n\r\nWhat does all this mean? Let's look at the first instruction `LOAD_CONST` as an example. The number in the first column (`2`) shows the line number in our Python source code. The second column is an index into the bytecode, telling us that the `LOAD_CONST` instruction appears at position zero.  The third column is the instruction itself, mapped to its human-readable name. The fourth column, when present, is the argument to that instruction.  The fifth column, when present, is a hint about what the argument means.\r\n\r\nConsider the first few bytes of this bytecode: [100, 1, 0, 125, 0, 0]. These six bytes represent two instructions with their arguments. We can use `dis.opname`, a mapping from bytes to intelligible strings, to find out what instructions 100 and 125 map to:\r\n\r\n```python\r\n>>> dis.opname[100]\r\n'LOAD_CONST'\r\n>>> dis.opname[125]\r\n'STORE_FAST'\r\n```\r\n\r\nThe second and third bytes --- 1, 0 --- are arguments to `LOAD_CONST`, while the fifth and sixth bytes --- 0, 0 --- are arguments to `STORE_FAST`. Just like in our toy example, `LOAD_CONST` needs to know where to find its constant to load, and `STORE_FAST` needs to find the name to store. (Python's `LOAD_CONST` is the same as our toy interpreter's `LOAD_VALUE`, and `LOAD_FAST` is the same as `LOAD_NAME`.) So these six bytes represent the first line of code, `x = 3`. (Why use two bytes for each argument? If Python used just one byte to locate constants and names instead of two, you could only have 256 names/constants associated with a single code object. Using two bytes, you can have up to 256 squared, or 65,536.)\r\n\r\n### Conditionals and Loops\r\n\r\nSo far, the interpreter has executed code simply by stepping through the instructions one by one. This is a problem; often, we want to execute certain instructions many times, or skip them under certain conditions. To allow us to write loops and if statements in our code, the interpreter must be able to jump around in the instruction set. In a sense, Python handles loops and conditionals with `GOTO` statements in the bytecode! Look at the disassembly of the function `cond` again:\r\n\r\n```python\r\n>>> dis.dis(cond)\r\n  2           0 LOAD_CONST               1 (3)\r\n              3 STORE_FAST               0 (x)\r\n\r\n  3           6 LOAD_FAST                0 (x)\r\n              9 LOAD_CONST               2 (5)\r\n             12 COMPARE_OP               0 (<)\r\n             15 POP_JUMP_IF_FALSE       22\r\n\r\n  4          18 LOAD_CONST               3 ('yes')\r\n             21 RETURN_VALUE\r\n\r\n  6     >>   22 LOAD_CONST               4 ('no')\r\n             25 RETURN_VALUE\r\n             26 LOAD_CONST               0 (None)\r\n             29 RETURN_VALUE\r\n```\r\n\r\nThe conditional `if x < 5` on line 3 of the code is compiled into four instructions: `LOAD_FAST`, `LOAD_CONST`, `COMPARE_OP`, and `POP_JUMP_IF_FALSE`. `x < 5` generates code to load `x`, load 5, and compare the two values. The instruction `POP_JUMP_IF_FALSE` is responsible for implementing the `if`. This instruction will pop the top value off the interpreter's stack. If the value is true, then nothing happens. (The value can be \"truthy\" --- it doesn't have to be the literal `True` object.) If the value is false, then the interpreter will jump to another instruction.\r\n\r\nThe instruction to land on is called the jump target, and it's provided as the argument to the `POP_JUMP` instruction. Here, the jump target is 22. The instruction at index 22 is `LOAD_CONST` on line 6. (`dis` marks jump targets with `>>`.) If the result of `x < 5` is False, then the interpreter will jump straight to line 6 (`return \"no\"`), skipping line 4 (`return \"yes\"`). Thus, the interpreter uses jump instructions to selectively skip over parts of the instruction set.\r\n\r\nPython loops also rely on jumping. In the bytecode below, notice that the line `while x < 5` generates almost identical bytecode to `if x < 10`. In both cases, the comparison is calculated and then `POP_JUMP_IF_FALSE` controls which instruction is executed next. At the end of line 4 --- the end of the loop's body --- the instruction `JUMP_ABSOLUTE` always sends the interpreter back to instruction 9 at the top of the loop. When x < 10 becomes false, then `POP_JUMP_IF_FALSE` jumps the interpreter past the end of the loop, to instruction 34. \r\n\r\n```python\r\n>>> def loop():\r\n...      x = 1\r\n...      while x < 5:\r\n...          x = x + 1\r\n...      return x\r\n...\r\n>>> dis.dis(loop)\r\n  2           0 LOAD_CONST               1 (1)\r\n              3 STORE_FAST               0 (x)\r\n\r\n  3           6 SETUP_LOOP              26 (to 35)\r\n        >>    9 LOAD_FAST                0 (x)\r\n             12 LOAD_CONST               2 (5)\r\n             15 COMPARE_OP               0 (<)\r\n             18 POP_JUMP_IF_FALSE       34\r\n\r\n  4          21 LOAD_FAST                0 (x)\r\n             24 LOAD_CONST               1 (1)\r\n             27 BINARY_ADD\r\n             28 STORE_FAST               0 (x)\r\n             31 JUMP_ABSOLUTE            9\r\n        >>   34 POP_BLOCK\r\n\r\n  5     >>   35 LOAD_FAST                0 (x)\r\n             38 RETURN_VALUE\r\n```\r\n\r\n### Explore Bytecode\r\n\r\nI encourage you to try running `dis.dis` on functions you write. Some interesting questions to explore are:\r\n\r\n- What's the difference between a for loop and a while loop to the Python interpreter?\r\n- How can you write different functions that generate identical bytecode?\r\n- How does `elif` work? What about list comprehensions?\r\n\r\n## Frames\r\n\r\nSo far, we've learned that the Python virtual machine is a stack machine. It steps and jumps through instructions, pushing and popping values on and off a stack. There are still some gaps in our mental model, though. In the examples above, the last instruction is `RETURN_VALUE`, which corresponds to the `return` statement in the code. But where does the instruction return to?\r\n\r\nTo answer this question, we must add one additional layer of complexity: the frame. A frame is a collection of information and context for a chunk of code. Frames are created and destroyed on the fly as your Python code executes. There's one frame corresponding to each *call* of a function --- so while each frame has one code object associated with it, a code object can have many frames. If you had a function that called itself recursively ten times, you'd have eleven frames --- one for each level of recursion and one for the module you started from. In general, there's a frame for each scope in a Python program. For example, each module, each function call, and each class definition has a frame.\r\n\r\nFrames live on the _call stack_, a completely different stack from the one we've been discussing so far. (The call stack is the stack you're most familiar with already --- you've seen it printed out in the tracebacks of exceptions. Each line in a traceback starting with \"File 'program.py', line 10\" corresponds to one frame on the call stack.) The stack we've been examining --- the one the interpreter is manipulating while it executes bytecode --- we'll call the _data stack_. There's also a third stack, called the _block stack_. Blocks are used for certain kinds of control flow, particularly looping and exception handling. Each frame on the call stack has its own data stack and block stack.\r\n\r\nLet's make this concrete with an example. Suppose the Python interpreter is currently executing the line marked 3 below. The interpreter is in the middle of a call to `foo`, which is in turn calling `bar`. The diagram shows a schematic of the call stack of frames, the block stacks, and the data stacks. (This code is written like a REPL session, so we've first defined the needed functions.) At the moment we're interested in, the interpreter is executing `foo()`, at the bottom, which then reaches in to the body of `foo` and then up into `bar`.\r\n\r\n```python\r\n>>> def bar(y):\r\n...     z = y + 3     # <--- (3) ... and the interpreter is here.\r\n...     return z\r\n...\r\n>>> def foo():\r\n...     a = 1\r\n...     b = 2\r\n...     return a + bar(b) # <--- (2) ... which is returning a call to bar ...\r\n...\r\n>>> foo()             # <--- (1) We're in the middle of a call to foo ...\r\n3\r\n```\r\n\r\n\\aosafigure[240pt]{interpreter-images/interpreter-callstack.png}{The call stack}{500l.interpreter.callstack}\r\n\r\nAt this point, the interpreter is in the middle of the function call to `bar`. There are three frames on the call stack: one for the module level, one for the function `foo`, and one for `bar` (\\aosafigref{500l.interpreter.callstack}.) Once `bar` returns, the frame associated with it is popped off the call stack and discarded.\r\n\r\nThe bytecode instruction `RETURN_VALUE` tells the interpreter to pass a value between frames. First it will pop the top value off the data stack of the top frame on the call stack. Then it pops the entire frame off the call stack and throws it away. Finally, the value is pushed onto the data stack on the next frame down.\r\n\r\nWhen Ned Batchelder and I were working on Byterun, for a long time we had a significant error in our implementation. Instead of having one data stack on each frame, we had just one data stack on the entire virtual machine. We had dozens of tests made up of little snippets of Python code which we ran through Byterun and through the real Python interpreter to make sure the same thing happened in both interpreters. Nearly all of these tests were passing. The only thing we couldn't get working was generators. Finally, reading the CPython code more carefully, we realized the mistake[^thanks]. Moving a data stack onto each frame fixed the problem.\r\n\r\n[^thanks]: My thanks to Michael Arntzenius for his insight on this bug. \r\n\r\nLooking back on this bug, I was amazed at how little of Python relied on each frame having a different data stack. Nearly all operations in the Python interpreter carefully clean up the data stack, so the fact that the frames were sharing the same stack didn't matter. In the example above, when `bar` finishes executing, it'll leave its data stack empty. Even if `foo` shared the same stack, the values would be lower down. However, with generators, a key feature is the ability to pause a frame, return to some other frame, and then return to the generator frame later and have it be in exactly the same state that you left it.\r\n\r\n## Byterun\r\n\r\nWe now have enough context about the Python interpreter to begin examining Byterun. \r\n\r\nThere are four kinds of objects in Byterun:\r\n\r\n- A `VirtualMachine` class, which manages the highest-level structure, particularly the call stack of frames, and contains a mapping of instructions to operations. This is a more complex version of the `Intepreter` object above.\r\n- A `Frame` class.  Every `Frame` instance has one code object and manages a few other necessary bits of state, particularly the global and local namespaces, a reference to the calling frame, and the last bytecode instruction executed.\r\n- A `Function` class, which will be used in place of real Python functions. Recall that calling a function creates a new frame in the interpreter. We implement Function so that we control the creation of new Frames.\r\n- A `Block` class, which just wraps the three attributes of blocks. (The details of blocks aren't central to the Python interpreter, so we won't spend much time on them, but they're included here so that Byterun can run real Python code.)\r\n\r\n### The `VirtualMachine` Class\r\n\r\nOnly one instance of `VirtualMachine` will be created each time the program is run, because we only have one Python interpreter. `VirtualMachine` stores the call stack, the exception state, and return values while they're being passed between frames. The entry point for executing code is the method `run_code`, which takes a compiled code object as an argument. It starts by setting up and running a frame. This frame may create other frames; the call stack will grow and shrink as the program executes. When the first frame eventually returns, execution is finished.\r\n\r\n```python\r\nclass VirtualMachineError(Exception):\r\n    pass\r\n\r\nclass VirtualMachine(object):\r\n    def __init__(self):\r\n        self.frames = []   # The call stack of frames.\r\n        self.frame = None  # The current frame.\r\n        self.return_value = None\r\n        self.last_exception = None\r\n\r\n    def run_code(self, code, global_names=None, local_names=None):\r\n        \"\"\" An entry point to execute code using the virtual machine.\"\"\"\r\n        frame = self.make_frame(code, global_names=global_names, \r\n                                local_names=local_names)\r\n        self.run_frame(frame)\r\n\r\n```\r\n\r\n### The `Frame` Class\r\n\r\nNext we'll write the `Frame` object. The frame is a collection of attributes with no methods. As mentioned above, the attributes include the code object created by the compiler; the local, global, and builtin namespaces; a reference to the previous frame; a data stack; a block stack; and the last instruction executed. (We have to do a little extra work to get to the builtin namespace because Python treats this namespace differently in different modules; this detail is not important to the virtual machine.)\r\n\r\n```python\r\nclass Frame(object):\r\n    def __init__(self, code_obj, global_names, local_names, prev_frame):\r\n        self.code_obj = code_obj\r\n        self.global_names = global_names\r\n        self.local_names = local_names\r\n        self.prev_frame = prev_frame\r\n        self.stack = []\r\n        if prev_frame:\r\n            self.builtin_names = prev_frame.builtin_names\r\n        else:\r\n            self.builtin_names = local_names['__builtins__']\r\n            if hasattr(self.builtin_names, '__dict__'):\r\n                self.builtin_names = self.builtin_names.__dict__\r\n\r\n        self.last_instruction = 0\r\n        self.block_stack = []\r\n```\r\n\r\nNext, we'll add frame manipulation to the virtual machine. There are three helper functions for frames: one to create new frames (which is responsible for sorting out the namespaces for the new frame) and one each to push and pop frames on and off the frame stack. A fourth function, `run_frame`, does the main work of executing a frame. We'll come back to this soon.\r\n\r\n```python\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    # Frame manipulation\r\n    def make_frame(self, code, callargs={}, global_names=None, local_names=None):\r\n        if global_names is not None and local_names is not None:\r\n            local_names = global_names\r\n        elif self.frames:\r\n            global_names = self.frame.global_names\r\n            local_names = {}\r\n        else:\r\n            global_names = local_names = {\r\n                '__builtins__': __builtins__,\r\n                '__name__': '__main__',\r\n                '__doc__': None,\r\n                '__package__': None,\r\n            }\r\n        local_names.update(callargs)\r\n        frame = Frame(code, global_names, local_names, self.frame)\r\n        return frame\r\n\r\n    def push_frame(self, frame):\r\n        self.frames.append(frame)\r\n        self.frame = frame\r\n\r\n    def pop_frame(self):\r\n        self.frames.pop()\r\n        if self.frames:\r\n            self.frame = self.frames[-1]\r\n        else:\r\n            self.frame = None\r\n\r\n    def run_frame(self):\r\n        pass\r\n        # we'll come back to this shortly\r\n```\r\n\r\n### The `Function` Class\r\n\r\nThe implementation of the `Function` object is somewhat twisty, and most of the details aren't critical to understanding the interpreter. The important thing to notice is that calling a function --- invoking the `__call__` method --- creates a new `Frame` object and starts running it.\r\n\r\n```python\r\nclass Function(object):\r\n    \"\"\"\r\n    Create a realistic function object, defining the things the interpreter expects.\r\n    \"\"\"\r\n    __slots__ = [\r\n        'func_code', 'func_name', 'func_defaults', 'func_globals',\r\n        'func_locals', 'func_dict', 'func_closure',\r\n        '__name__', '__dict__', '__doc__',\r\n        '_vm', '_func',\r\n    ]\r\n\r\n    def __init__(self, name, code, globs, defaults, closure, vm):\r\n        \"\"\"You don't need to follow this closely to understand the interpreter.\"\"\"\r\n        self._vm = vm\r\n        self.func_code = code\r\n        self.func_name = self.__name__ = name or code.co_name\r\n        self.func_defaults = tuple(defaults)\r\n        self.func_globals = globs\r\n        self.func_locals = self._vm.frame.f_locals\r\n        self.__dict__ = {}\r\n        self.func_closure = closure\r\n        self.__doc__ = code.co_consts[0] if code.co_consts else None\r\n\r\n        # Sometimes, we need a real Python function.  This is for that.\r\n        kw = {\r\n            'argdefs': self.func_defaults,\r\n        }\r\n        if closure:\r\n            kw['closure'] = tuple(make_cell(0) for _ in closure)\r\n        self._func = types.FunctionType(code, globs, **kw)\r\n\r\n    def __call__(self, *args, **kwargs):\r\n        \"\"\"When calling a Function, make a new frame and run it.\"\"\"\r\n        callargs = inspect.getcallargs(self._func, *args, **kwargs)\r\n        # Use callargs to provide a mapping of arguments: values to pass into the new \r\n        # frame.\r\n        frame = self._vm.make_frame(\r\n            self.func_code, callargs, self.func_globals, {}\r\n        )\r\n        return self._vm.run_frame(frame)\r\n\r\ndef make_cell(value):\r\n    \"\"\"Create a real Python closure and grab a cell.\"\"\"\r\n    # Thanks to Alex Gaynor for help with this bit of twistiness.\r\n    fn = (lambda x: lambda: x)(value)\r\n    return fn.__closure__[0]\r\n```\r\n\r\nNext, back on the `VirtualMachine` object, we'll add some helper methods for data stack manipulation. The bytecodes that manipulate the stack always operate on the current frame's data stack. This will make our implementations of `POP_TOP`, `LOAD_FAST`, and all the other instructions that touch the stack more readable.\r\n\r\n```python\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    # Data stack manipulation\r\n    def top(self):\r\n        return self.frame.stack[-1]\r\n\r\n    def pop(self):\r\n        return self.frame.stack.pop()\r\n\r\n    def push(self, *vals):\r\n        self.frame.stack.extend(vals)\r\n\r\n    def popn(self, n):\r\n        \"\"\"Pop a number of values from the value stack.\r\n        A list of `n` values is returned, the deepest value first.\r\n        \"\"\"\r\n        if n:\r\n            ret = self.frame.stack[-n:]\r\n            self.frame.stack[-n:] = []\r\n            return ret\r\n        else:\r\n            return []\r\n```\r\n\r\nBefore we get to running a frame, we need two more methods. \r\n\r\nThe first, `parse_byte_and_args`, takes a bytecode, checks if it has arguments, and parses the arguments if so. This method also updates the frame's attribute `last_instruction`, a reference to the last instruction executed. A single instruction is one byte long if it doesn't have an argument, and three bytes if it does have an argument; the last two bytes are the argument.  The meaning of the argument to each instruction depends on which instruction it is. For example, as mentioned above, for `POP_JUMP_IF_FALSE`, the argument to the instruction is the jump target.  For `BUILD_LIST`, the argument is the number of elements in the list. For `LOAD_CONST`, it's an index into the list of constants.\r\n\r\nSome instructions use simple numbers as their arguments. For others, the virtual machine has to do a little work to discover what the arguments mean.  The `dis` module in the standard library exposes a cheatsheet explaining what arguments have what meaning, which makes our code more compact.  For example, the list `dis.hasname` tells us that the arguments to `LOAD_NAME`, `IMPORT_NAME`, `LOAD_GLOBAL`, and nine other instructions have the same meaning: for these instructions, the argument represents an index into the list of names on the code object.\r\n\r\n```python\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    def parse_byte_and_args(self):\r\n        f = self.frame\r\n        opoffset = f.last_instruction\r\n        byteCode = f.code_obj.co_code[opoffset]\r\n        f.last_instruction += 1\r\n        byte_name = dis.opname[byteCode]\r\n        if byteCode >= dis.HAVE_ARGUMENT:\r\n            # index into the bytecode\r\n            arg = f.code_obj.co_code[f.last_instruction:f.last_instruction+2]  \r\n            f.last_instruction += 2   # advance the instruction pointer\r\n            arg_val = arg[0] + (arg[1] * 256)\r\n            if byteCode in dis.hasconst:   # Look up a constant\r\n                arg = f.code_obj.co_consts[arg_val]\r\n            elif byteCode in dis.hasname:  # Look up a name\r\n                arg = f.code_obj.co_names[arg_val]\r\n            elif byteCode in dis.haslocal: # Look up a local name\r\n                arg = f.code_obj.co_varnames[arg_val]\r\n            elif byteCode in dis.hasjrel:  # Calculate a relative jump\r\n                arg = f.last_instruction + arg_val\r\n            else:\r\n                arg = arg_val\r\n            argument = [arg]\r\n        else:\r\n            argument = []\r\n\r\n        return byte_name, argument\r\n```\r\n\r\nThe next method is `dispatch`, which looks up the operations for a given instruction and executes them. In the CPython interpreter, this dispatch is done with a giant switch statement that spans 1,500 lines!  Luckily, since we're writing Python, we can be more compact.  We'll define a method for each byte name and then use `getattr` to look it up. Like in the toy interpreter above, if our instruction is named `FOO_BAR`, the corresponding method would be named `byte_FOO_BAR`. For the moment, we'll leave the content of these methods as a black box.  Each bytecode method will return either `None` or a string, called `why`, which is an extra piece of state the interpreter needs in some cases.  These return values of the individual instruction methods are used only as internal indicators of interpreter state --- don't confuse these with return values from executing frames.\r\n\r\n\r\n```python\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    def dispatch(self, byte_name, argument):\r\n        \"\"\" Dispatch by bytename to the corresponding methods.\r\n        Exceptions are caught and set on the virtual machine.\"\"\"\r\n\r\n        # When later unwinding the block stack,\r\n        # we need to keep track of why we are doing it.\r\n        why = None\r\n        try:\r\n            bytecode_fn = getattr(self, 'byte_%s' % byte_name, None)\r\n            if bytecode_fn is None:\r\n                if byte_name.startswith('UNARY_'):\r\n                    self.unaryOperator(byte_name[6:])\r\n                elif byte_name.startswith('BINARY_'):\r\n                    self.binaryOperator(byte_name[7:])\r\n                else:\r\n                    raise VirtualMachineError(\r\n                        \"unsupported bytecode type: %s\" % byte_name\r\n                    )\r\n            else:\r\n                why = bytecode_fn(*argument)\r\n        except:\r\n            # deal with exceptions encountered while executing the op.\r\n            self.last_exception = sys.exc_info()[:2] + (None,)\r\n            why = 'exception'\r\n\r\n        return why\r\n\r\n    def run_frame(self, frame):\r\n        \"\"\"Run a frame until it returns (somehow).\r\n        Exceptions are raised, the return value is returned.\r\n        \"\"\"\r\n        self.push_frame(frame)\r\n        while True:\r\n            byte_name, arguments = self.parse_byte_and_args()\r\n\r\n            why = self.dispatch(byte_name, arguments)\r\n\r\n            # Deal with any block management we need to do\r\n            while why and frame.block_stack:\r\n                why = self.manage_block_stack(why)\r\n\r\n            if why:\r\n                break\r\n\r\n        self.pop_frame()\r\n\r\n        if why == 'exception':\r\n            exc, val, tb = self.last_exception\r\n            e = exc(val)\r\n            e.__traceback__ = tb\r\n            raise e\r\n\r\n        return self.return_value\r\n```\r\n\r\n### The `Block` Class\r\n\r\nBefore we implement the methods for each bytecode instruction, we'll briefly discuss blocks. A block is used for certain kinds of flow control, specifically exception handling and looping. The block is reponsible for making sure that the data stack is in the appropriate state when the operation is finished.  For example, in a loop, a special iterator object remains on the stack while the loop is running, but is popped off when it is finished. The interpreter must keep track of whether the loop is continuing or is finished.\r\n\r\nTo keep track of this extra piece of information, the interpreter sets a flag to indicate its state.  We implement this flag as a variable called `why`, which can be `None` or one of the strings `\"continue\"`, `\"break\"`, `\"exception\"`, or `\"return\"`. This indicates what kind of manipulation of the block stack and data stack should happen.  To return to the iterator example, if the top of the block stack is a `loop` block and the `why` code is `continue`, the iterator object should remain on the data stack, but if the `why` code is `break`, it should be popped off.\r\n\r\nThe precise details of block manipulation are rather fiddly, and we won't spend more time on this, but interested readers are encouraged to take a careful look.\r\n\r\n```python\r\nBlock = collections.namedtuple(\"Block\", \"type, handler, stack_height\")\r\n\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    # Block stack manipulation\r\n    def push_block(self, b_type, handler=None):\r\n        level = len(self.frame.stack)\r\n        self.frame.block_stack.append(Block(b_type, handler, stack_height))\r\n\r\n    def pop_block(self):\r\n        return self.frame.block_stack.pop()\r\n\r\n    def unwind_block(self, block):\r\n        \"\"\"Unwind the values on the data stack corresponding to a given block.\"\"\"\r\n        if block.type == 'except-handler':\r\n            # The exception itself is on the stack as type, value, and traceback.\r\n            offset = 3  \r\n        else:\r\n            offset = 0\r\n\r\n        while len(self.frame.stack) > block.level + offset:\r\n            self.pop()\r\n\r\n        if block.type == 'except-handler':\r\n            traceback, value, exctype = self.popn(3)\r\n            self.last_exception = exctype, value, traceback\r\n\r\n    def manage_block_stack(self, why):\r\n        \"\"\" \"\"\"\r\n        frame = self.frame\r\n        block = frame.block_stack[-1]\r\n        if block.type == 'loop' and why == 'continue':\r\n            self.jump(self.return_value)\r\n            why = None\r\n            return why\r\n\r\n        self.pop_block()\r\n        self.unwind_block(block)\r\n\r\n        if block.type == 'loop' and why == 'break':\r\n            why = None\r\n            self.jump(block.handler)\r\n            return why\r\n\r\n        if (block.type in ['setup-except', 'finally'] and why == 'exception'):\r\n            self.push_block('except-handler')\r\n            exctype, value, tb = self.last_exception\r\n            self.push(tb, value, exctype)\r\n            self.push(tb, value, exctype) # yes, twice\r\n            why = None\r\n            self.jump(block.handler)\r\n            return why\r\n\r\n        elif block.type == 'finally':\r\n            if why in ('return', 'continue'):\r\n                self.push(self.return_value)\r\n\r\n            self.push(why)\r\n\r\n            why = None\r\n            self.jump(block.handler)\r\n            return why\r\n        return why\r\n```\r\n\r\n## The Instructions\r\n\r\nAll that's left is to implement the dozens of methods for instructions: `byte_LOAD_FAST`, `byte_BINARY_MODULO`, and so on. The actual instructions are the least interesting part of the interpreter, so we show only a handful here, but the full implementation is available at https://github.com/nedbat/byterun. (Enough instructions are included here to execute all the code samples that we disassembled above.)\r\n\r\n```python\r\nclass VirtualMachine(object):\r\n    [... snip ...]\r\n\r\n    ## Stack manipulation\r\n\r\n    def byte_LOAD_CONST(self, const):\r\n        self.push(const)\r\n\r\n    def byte_POP_TOP(self):\r\n        self.pop()\r\n\r\n    ## Names\r\n    def byte_LOAD_NAME(self, name):\r\n        frame = self.frame\r\n        if name in frame.f_locals:\r\n            val = frame.f_locals[name]\r\n        elif name in frame.f_globals:\r\n            val = frame.f_globals[name]\r\n        elif name in frame.f_builtins:\r\n            val = frame.f_builtins[name]\r\n        else:\r\n            raise NameError(\"name '%s' is not defined\" % name)\r\n        self.push(val)\r\n\r\n    def byte_STORE_NAME(self, name):\r\n        self.frame.f_locals[name] = self.pop()\r\n\r\n    def byte_LOAD_FAST(self, name):\r\n        if name in self.frame.f_locals:\r\n            val = self.frame.f_locals[name]\r\n        else:\r\n            raise UnboundLocalError(\r\n                \"local variable '%s' referenced before assignment\" % name\r\n            )\r\n        self.push(val)\r\n\r\n    def byte_STORE_FAST(self, name):\r\n        self.frame.f_locals[name] = self.pop()\r\n\r\n    def byte_LOAD_GLOBAL(self, name):\r\n        f = self.frame\r\n        if name in f.f_globals:\r\n            val = f.f_globals[name]\r\n        elif name in f.f_builtins:\r\n            val = f.f_builtins[name]\r\n        else:\r\n            raise NameError(\"global name '%s' is not defined\" % name)\r\n        self.push(val)\r\n\r\n    ## Operators\r\n\r\n    BINARY_OPERATORS = {\r\n        'POWER':    pow,\r\n        'MULTIPLY': operator.mul,\r\n        'FLOOR_DIVIDE': operator.floordiv,\r\n        'TRUE_DIVIDE':  operator.truediv,\r\n        'MODULO':   operator.mod,\r\n        'ADD':      operator.add,\r\n        'SUBTRACT': operator.sub,\r\n        'SUBSCR':   operator.getitem,\r\n        'LSHIFT':   operator.lshift,\r\n        'RSHIFT':   operator.rshift,\r\n        'AND':      operator.and_,\r\n        'XOR':      operator.xor,\r\n        'OR':       operator.or_,\r\n    }\r\n\r\n    def binaryOperator(self, op):\r\n        x, y = self.popn(2)\r\n        self.push(self.BINARY_OPERATORS[op](x, y))\r\n\r\n    COMPARE_OPERATORS = [\r\n        operator.lt,\r\n        operator.le,\r\n        operator.eq,\r\n        operator.ne,\r\n        operator.gt,\r\n        operator.ge,\r\n        lambda x, y: x in y,\r\n        lambda x, y: x not in y,\r\n        lambda x, y: x is y,\r\n        lambda x, y: x is not y,\r\n        lambda x, y: issubclass(x, Exception) and issubclass(x, y),\r\n    ]\r\n\r\n    def byte_COMPARE_OP(self, opnum):\r\n        x, y = self.popn(2)\r\n        self.push(self.COMPARE_OPERATORS[opnum](x, y))\r\n\r\n    ## Attributes and indexing\r\n\r\n    def byte_LOAD_ATTR(self, attr):\r\n        obj = self.pop()\r\n        val = getattr(obj, attr)\r\n        self.push(val)\r\n\r\n    def byte_STORE_ATTR(self, name):\r\n        val, obj = self.popn(2)\r\n        setattr(obj, name, val)\r\n\r\n    ## Building\r\n\r\n    def byte_BUILD_LIST(self, count):\r\n        elts = self.popn(count)\r\n        self.push(elts)\r\n\r\n    def byte_BUILD_MAP(self, size):\r\n        self.push({})\r\n\r\n    def byte_STORE_MAP(self):\r\n        the_map, val, key = self.popn(3)\r\n        the_map[key] = val\r\n        self.push(the_map)\r\n\r\n    def byte_LIST_APPEND(self, count):\r\n        val = self.pop()\r\n        the_list = self.frame.stack[-count] # peek\r\n        the_list.append(val)\r\n\r\n    ## Jumps\r\n\r\n    def byte_JUMP_FORWARD(self, jump):\r\n        self.jump(jump)\r\n\r\n    def byte_JUMP_ABSOLUTE(self, jump):\r\n        self.jump(jump)\r\n\r\n    def byte_POP_JUMP_IF_TRUE(self, jump):\r\n        val = self.pop()\r\n        if val:\r\n            self.jump(jump)\r\n\r\n    def byte_POP_JUMP_IF_FALSE(self, jump):\r\n        val = self.pop()\r\n        if not val:\r\n            self.jump(jump)\r\n\r\n    ## Blocks\r\n\r\n    def byte_SETUP_LOOP(self, dest):\r\n        self.push_block('loop', dest)\r\n\r\n    def byte_GET_ITER(self):\r\n        self.push(iter(self.pop()))\r\n\r\n    def byte_FOR_ITER(self, jump):\r\n        iterobj = self.top()\r\n        try:\r\n            v = next(iterobj)\r\n            self.push(v)\r\n        except StopIteration:\r\n            self.pop()\r\n            self.jump(jump)\r\n\r\n    def byte_BREAK_LOOP(self):\r\n        return 'break'\r\n\r\n    def byte_POP_BLOCK(self):\r\n        self.pop_block()\r\n\r\n    ## Functions\r\n\r\n    def byte_MAKE_FUNCTION(self, argc):\r\n        name = self.pop()\r\n        code = self.pop()\r\n        defaults = self.popn(argc)\r\n        globs = self.frame.f_globals\r\n        fn = Function(name, code, globs, defaults, None, self)\r\n        self.push(fn)\r\n\r\n    def byte_CALL_FUNCTION(self, arg):\r\n        lenKw, lenPos = divmod(arg, 256) # KWargs not supported here\r\n        posargs = self.popn(lenPos)\r\n\r\n        func = self.pop()\r\n        frame = self.frame\r\n        retval = func(*posargs)\r\n        self.push(retval)\r\n\r\n    def byte_RETURN_VALUE(self):\r\n        self.return_value = self.pop()\r\n        return \"return\"\r\n```\r\n\r\n## Dynamic Typing: What the Compiler Doesn't Know\r\n\r\nOne thing you've probably heard is that Python is a \"dynamic\" language --- particularly that it's \"dynamically typed\". The context we've just built up on the interpreter sheds some light on this description.\r\n\r\nOne of the things \"dynamic\" means in this context is that a lot of work is done at run time. We saw earlier that the Python compiler doesn't have much information about what the code actually does. For example, consider the short function `mod` below. `mod` takes two arguments and returns the first modulo the second. In the bytecode, we see that the variables `a` and `b` are loaded, then the bytecode `BINARY_MODULO` performs the modulo operation itself.\r\n\r\n```python\r\n>>> def mod(a, b):\r\n...    return a % b\r\n>>> dis.dis(mod)\r\n  2           0 LOAD_FAST                0 (a)\r\n              3 LOAD_FAST                1 (b)\r\n              6 BINARY_MODULO\r\n              7 RETURN_VALUE\r\n>>> mod(19, 5)\r\n4\r\n```\r\n\r\nCalculating 19 `%` 5 yields 4 --- no surprise there. What happens if we call it with different kinds of arguments?\r\n\r\n```python\r\n>>> mod(\"by%sde\", \"teco\")\r\n'bytecode'\r\n```\r\n\r\nWhat just happened? You've probably seen this syntax before, but in a different context: string formatting.\r\n\r\n```\r\n>>> print(\"by%sde\" % \"teco\")\r\nbytecode\r\n```\r\n\r\nUsing the symbol `%` to format a string for printing means invoking the instruction `BINARY_MODULO`. This instruction mods together the top two values on the stack when the instruction executes --- regardless of whether they're strings, integers, or instances of a class you defined yourself. The bytecode was generated when the function was compiled (effectively, when it was defined) and the same bytecode is used with different types of arguments.\r\n\r\nThe Python compiler knows relatively little about the effect the bytecode will have. It's up to the interpreter to determine the type of the object that `BINARY_MODULO` is operating on and do the right thing for that type. This is why Python is described as _dynamically typed_: you don't know the types of the arguments to this function until you actually run it. By contrast, in a language that's statically typed, the programmer tells the compiler up front what type the arguments will be (or the compiler figures them out for itself).\r\n\r\nThe compiler's ignorance is one of the challenges to optimizing Python or analyzing it statically --- just looking at the bytecode, without actually running the code, you don't know what each instruction will do! In fact, you could define a class that implements the `__mod__` method, and Python would invoke that method if you use `%` on your objects. So `BINARY_MODULO` could actually run any code at all!\r\n\r\nJust looking at the following code, the first calculation of `a % b` seems wasteful.\r\n\r\n```python\r\ndef mod(a,b):\r\n    a % b\r\n    return a %b\r\n```\r\n\r\nUnfortunately, a static analysis of this code --- the kind of you can do without running it --- can't be certain that the first `a % b` really does nothing. Calling `__mod__` with `%` might write to a file, or interact with another part of your program, or do literally anything else that's possible in Python. It's hard to optimize a function when you don't know what it does! In Russell Power and Alex Rubinsteyn's great paper \"How fast can we make interpreted Python?\", they note, \"In the general absence of type information, each instruction must be treated as `INVOKE_ARBITRARY_METHOD`.\"\r\n\r\n## Conclusion\r\n\r\nByterun is a compact Python interpreter that's easier to understand than CPython. Byterun replicates CPython's primary structural details: a stack-based interpreter operating on instruction sets called bytecode. It steps or jumps through these instructions, pushing to and popping from a stack of data. The interpreter creates, destroys, and jumps between frames as it calls into and returns from functions and generators. Byterun shares the real interpreter's limitations, too: because Python uses dynamic typing, the interpreter must work hard at run time to determine the correct behavior for any series of instructions.\r\n\r\nI encourage you to disassemble your own programs and to run them using Byterun. You'll quickly run into instructions that this shorter version of Byterun doesn't implement. The full implementation can be found at https://github.com/nedbat/byterun --- or, by carefully reading the real CPython interpreter's `ceval.c`, you can implement it yourself!\r\n\r\n## Acknowledgements\r\n\r\nThanks to Ned Batchelder for originating this project and guiding my contributions, Michael Arntzenius for his help debugging the code and editing the prose, Leta Montopoli for her edits, and the entire Recurse Center community for their support and interest. Any errors are my own.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}